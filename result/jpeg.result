PyTorch Version:  1.0.0
Torchvision Version:  0.2.1
Namespace(add_jpeg_layer=True, batch_size=8, data_dir='/data/jenna/data/', feature_extract=False, model_name='resnet', num_classes=3, num_epochs=12, qtable=False, rand_qtable=False, regularize=False, visualize=True)
Sequential(
  (0): JpegLayer()
  (1): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)
    (fc): Linear(in_features=512, out_features=3, bias=True)
  )
)
Initializing Datasets and Dataloaders...
Params to learn:
['1.conv1.weight', '1.bn1.weight', '1.bn1.bias', '1.layer1.0.conv1.weight', '1.layer1.0.bn1.weight', '1.layer1.0.bn1.bias', '1.layer1.0.conv2.weight', '1.layer1.0.bn2.weight', '1.layer1.0.bn2.bias', '1.layer1.1.conv1.weight', '1.layer1.1.bn1.weight', '1.layer1.1.bn1.bias', '1.layer1.1.conv2.weight', '1.layer1.1.bn2.weight', '1.layer1.1.bn2.bias', '1.layer2.0.conv1.weight', '1.layer2.0.bn1.weight', '1.layer2.0.bn1.bias', '1.layer2.0.conv2.weight', '1.layer2.0.bn2.weight', '1.layer2.0.bn2.bias', '1.layer2.0.downsample.0.weight', '1.layer2.0.downsample.1.weight', '1.layer2.0.downsample.1.bias', '1.layer2.1.conv1.weight', '1.layer2.1.bn1.weight', '1.layer2.1.bn1.bias', '1.layer2.1.conv2.weight', '1.layer2.1.bn2.weight', '1.layer2.1.bn2.bias', '1.layer3.0.conv1.weight', '1.layer3.0.bn1.weight', '1.layer3.0.bn1.bias', '1.layer3.0.conv2.weight', '1.layer3.0.bn2.weight', '1.layer3.0.bn2.bias', '1.layer3.0.downsample.0.weight', '1.layer3.0.downsample.1.weight', '1.layer3.0.downsample.1.bias', '1.layer3.1.conv1.weight', '1.layer3.1.bn1.weight', '1.layer3.1.bn1.bias', '1.layer3.1.conv2.weight', '1.layer3.1.bn2.weight', '1.layer3.1.bn2.bias', '1.layer4.0.conv1.weight', '1.layer4.0.bn1.weight', '1.layer4.0.bn1.bias', '1.layer4.0.conv2.weight', '1.layer4.0.bn2.weight', '1.layer4.0.bn2.bias', '1.layer4.0.downsample.0.weight', '1.layer4.0.downsample.1.weight', '1.layer4.0.downsample.1.bias', '1.layer4.1.conv1.weight', '1.layer4.1.bn1.weight', '1.layer4.1.bn1.bias', '1.layer4.1.conv2.weight', '1.layer4.1.bn2.weight', '1.layer4.1.bn2.bias', '1.fc.weight', '1.fc.bias']
Epoch 0/11
----------
train Loss: 0.2592 Acc: 0.9111
val Loss: 0.5101 Acc: 0.8687

Epoch 1/11
----------
train Loss: 0.1807 Acc: 0.9401
val Loss: 0.2364 Acc: 0.9160

Epoch 2/11
----------
train Loss: 0.1576 Acc: 0.9499
val Loss: 0.4321 Acc: 0.8761

Epoch 3/11
----------
train Loss: 0.1189 Acc: 0.9633
val Loss: 0.3172 Acc: 0.9019

Epoch 4/11
----------
train Loss: 0.1121 Acc: 0.9627
val Loss: 0.4404 Acc: 0.8828

Epoch 5/11
----------
train Loss: 0.1314 Acc: 0.9612
val Loss: 0.2982 Acc: 0.8953

Epoch 6/11
----------
train Loss: 0.0945 Acc: 0.9665
val Loss: 0.5640 Acc: 0.8595

Epoch 7/11
----------
train Loss: 0.0970 Acc: 0.9695
val Loss: 0.5239 Acc: 0.8662

Epoch 8/11
----------
train Loss: 0.0872 Acc: 0.9707
val Loss: 0.5528 Acc: 0.8645

Epoch 9/11
----------
train Loss: 0.0844 Acc: 0.9745
val Loss: 0.3918 Acc: 0.8803

Epoch 10/11
----------
train Loss: 0.0697 Acc: 0.9784
val Loss: 0.6195 Acc: 0.8371

Epoch 11/11
----------
train Loss: 0.0765 Acc: 0.9745
